{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self, filters=(256, 256, 256, 128, 128), kernels=(8,)*5, input_channels=64):\n",
    "        super(Extractor, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for filter_, kernel in zip(filters, kernels):\n",
    "            self.layers.append(nn.Conv1d(input_channels, filter_, kernel))\n",
    "            self.layers.append(nn.LeakyReLU())  # LayerNorm added later in the forward method\n",
    "            self.layers.append(nn.ConstantPad1d((0, kernel - 1), 0))\n",
    "            input_channels = filter_\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            # Apply LayerNorm after each LeakyReLU\n",
    "            if isinstance(layer, nn.LeakyReLU):\n",
    "                norm_shape = x.shape[1:]\n",
    "                x = nn.LayerNorm(norm_shape).to(x.device)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class OutputContext(nn.Module):\n",
    "    def __init__(self, filter_=64, kernel=32, input_channels=64):\n",
    "        super(OutputContext, self).__init__()\n",
    "        self.pad = nn.ConstantPad1d((kernel - 1, 0), 0)\n",
    "        self.conv = nn.Conv1d(input_channels, filter_, kernel)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        # LayerNorm added later in the forward method\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        norm_shape = x.shape[1:]\n",
    "        x = nn.LayerNorm(norm_shape).to(x.device)(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "class VLAAI(nn.Module):\n",
    "    def __init__(self, nb_blocks=4, input_channels=64, output_dim=1, use_skip=True, extractor_output = 128):\n",
    "        super(VLAAI, self).__init__()\n",
    "        self.nb_blocks = nb_blocks\n",
    "        self.use_skip = use_skip\n",
    "        self.extractor = Extractor(input_channels=input_channels)\n",
    "        self.dense = nn.Linear(extractor_output, input_channels)  # Equivalent of Dense in TF\n",
    "        self.output_context = OutputContext(input_channels=input_channels)\n",
    "        self.final_dense = nn.Linear(input_channels, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.nb_blocks):\n",
    "            skip = x if self.use_skip else 0\n",
    "            x = self.extractor(x + skip)\n",
    "            print(x.shape)\n",
    "            x = x.transpose(1, 2)\n",
    "            print(x.shape)\n",
    "            x = self.dense(x)\n",
    "            x = x.transpose(1, 2)\n",
    "            x = self.output_context(x)\n",
    "            print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.final_dense(x)\n",
    "\n",
    "def pearson_corr(y_true, y_pred):\n",
    "    mean_true = y_true.mean(dim=1, keepdim=True)\n",
    "    mean_pred = y_pred.mean(dim=1, keepdim=True)\n",
    "    numerator = ((y_true - mean_true) * (y_pred - mean_pred)).sum(dim=1, keepdim=True)\n",
    "    std_true = ((y_true - mean_true) ** 2).sum(dim=1, keepdim=True).sqrt()\n",
    "    std_pred = ((y_pred - mean_pred) ** 2).sum(dim=1, keepdim=True).sqrt()\n",
    "    denominator = std_true * std_pred\n",
    "    return (numerator / (denominator + 1e-10))\n",
    "\n",
    "def pearson_loss(y_true, y_pred):\n",
    "    return -pearson_corr(y_true, y_pred)\n",
    "\n",
    "def pearson_metric(y_true, y_pred):\n",
    "    return pearson_corr(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 320])\n",
      "torch.Size([32, 320, 128])\n",
      "torch.Size([32, 64, 320])\n",
      "torch.Size([32, 128, 320])\n",
      "torch.Size([32, 320, 128])\n",
      "torch.Size([32, 64, 320])\n",
      "torch.Size([32, 128, 320])\n",
      "torch.Size([32, 320, 128])\n",
      "torch.Size([32, 64, 320])\n",
      "torch.Size([32, 128, 320])\n",
      "torch.Size([32, 320, 128])\n",
      "torch.Size([32, 64, 320])\n",
      "torch.Size([32, 320, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model = VLAAI()\n",
    "input_tensor = torch.rand(32, 64, 320)  # example input tensor with batch size 1, 64 channels, and length 100\n",
    "outputs = model(input_tensor)\n",
    "print(outputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
