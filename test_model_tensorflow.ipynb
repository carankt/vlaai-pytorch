{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code to construct the VLAAI network.\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def extractor(\n",
    "    filters=(256, 256, 256, 128, 128),\n",
    "    kernels=(8,) * 5,\n",
    "    input_channels=64,\n",
    "    normalization_fn=lambda x: tf.keras.layers.LayerNormalization()(x),\n",
    "    activation_fn=lambda x: tf.keras.layers.LeakyReLU()(x),\n",
    "    name=\"extractor\",\n",
    "):\n",
    "    \"\"\"Construct the extractor model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filters: Sequence[int]\n",
    "        Number of filters for each layer.\n",
    "    kernels: Sequence[int]\n",
    "        Kernel size for each layer.\n",
    "    input_channels: int\n",
    "        Number of EEG channels in the input\n",
    "    normalization_fn: Callable[[tf.Tensor], tf.Tensor]\n",
    "        Function to normalize the contents of a tensor.\n",
    "    activation_fn: Callable[[tf.Tensor], tf.Tensor]\n",
    "        Function to apply an activation function to the contents of a tensor.\n",
    "    name: str\n",
    "        Name of the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras.models.Model\n",
    "        The extractor model.\n",
    "    \"\"\"\n",
    "    eeg = tf.keras.layers.Input((None, input_channels))\n",
    "\n",
    "    x = eeg\n",
    "\n",
    "    if len(filters) != len(kernels):\n",
    "        raise ValueError(\"'filters' and 'kernels' must have the same length\")\n",
    "\n",
    "    # Add the convolutional layers\n",
    "    for filter_, kernel in zip(filters, kernels):\n",
    "        x = tf.keras.layers.Conv1D(filter_, kernel)(x)\n",
    "        x = normalization_fn(x)\n",
    "        x = activation_fn(x)\n",
    "        x = tf.keras.layers.ZeroPadding1D((0, kernel - 1))(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=[eeg], outputs=[x], name=name)\n",
    "\n",
    "\n",
    "def output_context(\n",
    "    filter_=64,\n",
    "    kernel=32,\n",
    "    input_channels=64,\n",
    "    normalization_fn=lambda x: tf.keras.layers.LayerNormalization()(x),\n",
    "    activation_fn=lambda x: tf.keras.layers.LeakyReLU()(x),\n",
    "    name=\"output_context_model\",\n",
    "):\n",
    "    \"\"\"Construct the output context model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filter_: int\n",
    "        Number of filters for the convolutional layer.\n",
    "    kernel: int\n",
    "        Kernel size for the convolutional layer.\n",
    "    input_channels: int\n",
    "        Number of EEG channels in the input.\n",
    "    normalization_fn: Callable[[tf.Tensor], tf.Tensor]\n",
    "        Function to normalize the contents of a tensor.\n",
    "    activation_fn: Callable[[tf.Tensor], tf.Tensor]\n",
    "        Function to apply an activation function to the contents of a tensor.\n",
    "    name: str\n",
    "        Name of the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras.models.Model\n",
    "        The output context model.\n",
    "    \"\"\"\n",
    "    inp = tf.keras.layers.Input((None, input_channels))\n",
    "    x = tf.keras.layers.ZeroPadding1D((kernel - 1, 0))(inp)\n",
    "    x = tf.keras.layers.Conv1D(filter_, kernel)(x)\n",
    "    x = normalization_fn(x)\n",
    "    x = activation_fn(x)\n",
    "    return tf.keras.models.Model(inputs=[inp], outputs=[x], name=name)\n",
    "\n",
    "\n",
    "def vlaai(\n",
    "    nb_blocks=4,\n",
    "    extractor_model=None,\n",
    "    output_context_model=None,\n",
    "    use_skip=True,\n",
    "    input_channels=64,\n",
    "    output_dim=1,\n",
    "    name=\"vlaai\",\n",
    "):\n",
    "    \"\"\"Construct the VLAAI model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nb_blocks: int\n",
    "        Number of repeated blocks to use.\n",
    "    extractor_model: Callable[[tf.Tensor], tf.Tensor]\n",
    "        The extractor model to use.\n",
    "    output_context_model: Callable[[tf.Tensor], tf.Tensor]\n",
    "        The output context model to use.\n",
    "    use_skip: bool\n",
    "        Whether to use skip connections.\n",
    "    input_channels: int\n",
    "        Number of EEG channels in the input.\n",
    "    output_dim: int\n",
    "        Number of output dimensions.\n",
    "    name: str\n",
    "        Name of the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras.models.Model\n",
    "        The VLAAI model.\n",
    "    \"\"\"\n",
    "    if extractor_model is None:\n",
    "        extractor_model = extractor()\n",
    "    if output_context_model is None:\n",
    "        output_context_model = output_context()\n",
    "\n",
    "    eeg = tf.keras.layers.Input((None, input_channels))\n",
    "\n",
    "    # If using skip connections: start with x set to zero\n",
    "    if use_skip:\n",
    "        x = tf.zeros_like(eeg)\n",
    "    else:\n",
    "        x = eeg\n",
    "\n",
    "    # Iterate over the blocks\n",
    "    for i in range(nb_blocks):\n",
    "        if use_skip:\n",
    "            x = extractor_model(eeg + x)\n",
    "        else:\n",
    "            x = extractor_model(x)\n",
    "        x = tf.keras.layers.Dense(input_channels)(x)\n",
    "        x = output_context_model(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(output_dim)(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=[eeg], outputs=[x], name=name)\n",
    "\n",
    "\n",
    "def pearson_tf(y_true, y_pred, axis=1):\n",
    "    \"\"\"Pearson correlation function implemented in tensorflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: tf.Tensor\n",
    "        Ground truth labels. Shape is (batch_size, time_steps, n_features)\n",
    "    y_pred: tf.Tensor\n",
    "        Predicted labels. Shape is (batch_size, time_steps, n_features)\n",
    "    axis: int\n",
    "        Axis along which to compute the pearson correlation. Default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        Pearson correlation.\n",
    "        Shape is (batch_size, 1, n_features) if axis is 1.\n",
    "    \"\"\"\n",
    "    # Compute the mean of the true and predicted values\n",
    "    y_true_mean = tf.reduce_mean(y_true, axis=axis, keepdims=True)\n",
    "    y_pred_mean = tf.reduce_mean(y_pred, axis=axis, keepdims=True)\n",
    "\n",
    "    # Compute the numerator and denominator of the pearson correlation\n",
    "    numerator = tf.reduce_sum(\n",
    "        (y_true - y_true_mean) * (y_pred - y_pred_mean),\n",
    "        axis=axis,\n",
    "        keepdims=True,\n",
    "    )\n",
    "    std_true = tf.reduce_sum(\n",
    "        tf.square(y_true - y_true_mean), axis=axis, keepdims=True\n",
    "    )\n",
    "    std_pred = tf.reduce_sum(\n",
    "        tf.square(y_pred - y_pred_mean), axis=axis, keepdims=True\n",
    "    )\n",
    "    denominator = tf.sqrt(std_true * std_pred)\n",
    "\n",
    "    # Compute the pearson correlation\n",
    "    return tf.math.divide_no_nan(numerator, denominator)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def pearson_loss(y_true, y_pred, axis=1):\n",
    "    \"\"\"Pearson loss function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: tf.Tensor\n",
    "        True values. Shape is (batch_size, time_steps, n_features)\n",
    "    y_pred: tf.Tensor\n",
    "        Predicted values. Shape is (batch_size, time_steps, n_features)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        Pearson loss.\n",
    "        Shape is (batch_size, 1, n_features)\n",
    "    \"\"\"\n",
    "    return -pearson_tf(y_true, y_pred, axis=axis)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def pearson_metric(y_true, y_pred, axis=1):\n",
    "    \"\"\"Pearson metric function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: tf.Tensor\n",
    "        True values. Shape is (batch_size, time_steps, n_features)\n",
    "    y_pred: tf.Tensor\n",
    "        Predicted values. Shape is (batch_size, time_steps, n_features)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.Tensor\n",
    "        Pearson metric.\n",
    "        Shape is (batch_size, 1, n_features)\n",
    "    \"\"\"\n",
    "    return pearson_tf(y_true, y_pred, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data for training and testing\n",
    "def generate_data(num_samples, time_steps, num_channels):\n",
    "    \"\"\"Generate synthetic EEG data and corresponding labels.\"\"\"\n",
    "    x = np.random.rand(num_samples, time_steps, num_channels).astype(np.float32)\n",
    "    # For simplicity, just make y some function of x\n",
    "    y = np.mean(x, axis=2, keepdims=True)  # Simple function of x\n",
    "    return x, y\n",
    "\n",
    "# Parameters\n",
    "num_samples = 32\n",
    "time_steps = 320\n",
    "num_channels = 64\n",
    "\n",
    "# Generate training and test data\n",
    "x_train, y_train = generate_data(num_samples, time_steps, num_channels)\n",
    "x_test, y_test = generate_data(200, time_steps, num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 320, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 320, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vlaai()\n",
    "model.compile(optimizer='adam', loss=pearson_loss, metrics=[pearson_metric])\n",
    "\n",
    "y_pred = model.predict(x_train)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/32 [====================>.........] - ETA: 9s - loss: -0.0509 - pearson_metric: 0.0509 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8df48d14ae3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and compile the model\n",
    "model = vlaai()\n",
    "model.compile(optimizer='adam', loss=pearson_loss, metrics=[pearson_metric])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, metric = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Pearson Metric: {metric}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Conv1D Layer 1: (None, None, 256)\n",
      "Output shape after Padding Layer 1: (None, None, 256)\n",
      "Output shape after Conv1D Layer 2: (None, None, 256)\n",
      "Output shape after Padding Layer 2: (None, None, 256)\n",
      "Output shape after Conv1D Layer 3: (None, None, 256)\n",
      "Output shape after Padding Layer 3: (None, None, 256)\n",
      "Output shape after Conv1D Layer 4: (None, None, 128)\n",
      "Output shape after Padding Layer 4: (None, None, 128)\n",
      "Output shape after Conv1D Layer 5: (None, None, 128)\n",
      "Output shape after Padding Layer 5: (None, None, 128)\n",
      "Final Model Summary:\n",
      "Model: \"extractor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 64)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 256)         131328    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, None, 256)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1 (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 256)         524544    \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, None, 256)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPaddin (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 256)         524544    \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, None, 256)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_2 (ZeroPaddin (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         262272    \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, None, 128)         256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_3 (ZeroPaddin (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         131200    \n",
      "_________________________________________________________________\n",
      "layer_normalization_4 (Layer (None, None, 128)         256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_4 (ZeroPaddin (None, None, 128)         0         \n",
      "=================================================================\n",
      "Total params: 1,575,936\n",
      "Trainable params: 1,575,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def extractor(\n",
    "    filters=(256, 256, 256, 128, 128),\n",
    "    kernels=(8,) * 5,\n",
    "    input_channels=64,\n",
    "    normalization_fn=lambda x: tf.keras.layers.LayerNormalization()(x),\n",
    "    activation_fn=lambda x: tf.keras.layers.LeakyReLU()(x),\n",
    "    name=\"extractor\",\n",
    "):\n",
    "    \"\"\"Construct the extractor model.\"\"\"\n",
    "\n",
    "    eeg = tf.keras.layers.Input((None, input_channels))\n",
    "    x = eeg\n",
    "\n",
    "    if len(filters) != len(kernels):\n",
    "        raise ValueError(\"'filters' and 'kernels' must have the same length\")\n",
    "\n",
    "    # Add the convolutional layers\n",
    "    for idx, (filter_, kernel) in enumerate(zip(filters, kernels)):\n",
    "        x = tf.keras.layers.Conv1D(filter_, kernel)(x)\n",
    "        print(f\"Output shape after Conv1D Layer {idx + 1}: {x.shape}\")\n",
    "        \n",
    "        x = normalization_fn(x)\n",
    "        x = activation_fn(x)\n",
    "        \n",
    "        x = tf.keras.layers.ZeroPadding1D((0, kernel - 1))(x)\n",
    "        print(f\"Output shape after Padding Layer {idx + 1}: {x.shape}\")\n",
    "\n",
    "    return tf.keras.models.Model(inputs=[eeg], outputs=[x], name=name)\n",
    "\n",
    "# Test\n",
    "model = extractor()\n",
    "print(\"Final Model Summary:\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Conv1D Layer 1: (None, None, 256)\n",
      "Output shape after Padding Layer 1: (None, None, 256)\n",
      "Output shape after Conv1D Layer 2: (None, None, 256)\n",
      "Output shape after Padding Layer 2: (None, None, 256)\n",
      "Output shape after Conv1D Layer 3: (None, None, 256)\n",
      "Output shape after Padding Layer 3: (None, None, 256)\n",
      "Output shape after Conv1D Layer 4: (None, None, 128)\n",
      "Output shape after Padding Layer 4: (None, None, 128)\n",
      "Output shape after Conv1D Layer 5: (None, None, 128)\n",
      "Output shape after Padding Layer 5: (None, None, 128)\n",
      "Output shape: (1, 320, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ... [extractor function code here] ...\n",
    "\n",
    "# Create a mock input tensor of shape (1, 1000, 64)\n",
    "mock_input = tf.random.normal((1, 320, 64))\n",
    "\n",
    "# Pass the mock input through the model\n",
    "model = extractor()\n",
    "output = model(mock_input)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('py36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cca9ec4f00471b6b76ecc07a8d539a9ff838c56f8f09dfc38947e6230b0fec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
